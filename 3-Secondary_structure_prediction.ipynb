{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Predicting protein secondary structures with GORIII</center></h1>\n",
    "\n",
    "Author: Rawad Ghostin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In previous parts, we've been focused on different methods of aligning protein sequences in order to study some of their features, like homology, similarity, and identity.<br>\n",
    "\n",
    "During alignments tasks, proteins are represented as a *flat* string of characters. From a more realistic point of view, proteins occupy space in 3 dimensions. Moreover, the spatial structure of a protein actively influences its functions biologically. Analyzing the structure of a protein is particularly significant in bioinformatics, as the shape of a protein affects its activity and its biochemical function. <br>\n",
    "In this project, we precisely focus on studying the following question:<br>\n",
    "**What is the structure of a given protein sequence? **<br>\n",
    "\n",
    "To answer this question, we will first explain protein structures in greater detail. Then, we will introduce available methods to determine such structures and implement a case study: the GOR3 algorithm.\n",
    "Finally, we will analyze, discuss and emit hypotheses about the results and performance of our structure predictions, which are based on a dataset we build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material and methods\n",
    "\n",
    "##  Protein structures\n",
    "The structure of a protein describes how the protein occupies 3-dimensional space. <br>\n",
    "Such structures actively influence the biological function of proteins and are important for extracting biological information, as to have a better understanding of the protein. In this section, we study different aspects of the protein structures.\n",
    "\n",
    "### Primary, secondary and tertiary structures\n",
    "The structure of a protein can be expressed by 3 forms of representations :\n",
    "- **Primary structure:**  This form is implicit in terms of providing information about the shape. In this form, only the type and order of amino acids is represented as a string.\n",
    "<figure>\n",
    "  <img src=\"img/s1.png\">\n",
    "  <figcaption>Fig.1 - Primary structure</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "- **Secondary structure:** In this form, amino acid residues are classified in various shape categories (Helix-$\\alpha$, $\\beta$-strands, and so forth).\n",
    "<figure>\n",
    "  <img src=\"img/secondary.png\">\n",
    "  <figcaption>Fig.2 - Secondary structure - Yellow: loop, Blue: Strand, Red: Helix</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "- **Tertiary structures:** This form is more explicit in terms of providing information about the shape. In addition to the shape categories introduced in the secondary structure, the tertiary structure expresses folds and angles by which the residues are arranged.\n",
    "  \n",
    "<figure>\n",
    "  <img src=\"img/tertiary.png\">\n",
    "  <figcaption>Fig.3 - Tertiary structure <figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Secondary structure shape classes\n",
    "In a protein, atoms can be chained by hydrogen bonds in various possible manners.<br>\n",
    "This has the effect of producing multiple shapes that influence the function of the protein.\n",
    "\n",
    "Mainly, the shapes we study are:\n",
    "- Helix-$\\alpha$ (H or G, I): molecular structure shaped as a helix\n",
    "<img src=\"img/helix.png\">\n",
    "\n",
    "- $\\beta$-strand (E or B) : molecular structure shaped as a strand or sheet\n",
    "<img src=\"img/beta.png\">\n",
    "\n",
    "\n",
    "\n",
    "- coil (C or T, S): molecular structure randomly shaped\n",
    "\n",
    "For simplification purposes, we will reduce the representations of the Helix-$\\alpha$ to `H`,$\\beta$-strand to `E` and coil to `C`.<br>\n",
    "This function `simplify_stype` is defined below, after importing useful modules to our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from math import log10\n",
    "from statistics import mean, stdev\n",
    "from matplotlib import pyplot as plt\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_stype(stype):\n",
    "    if stype in {'H', 'G', 'I'}:\n",
    "        return 'H'\n",
    "    elif stype in {'E', 'B'}:\n",
    "        return 'E'\n",
    "    elif stype in {'T', 'C', 'S', ' '}:\n",
    "        return 'C'\n",
    "    else:\n",
    "        raise Exception(\"Unrecognized structure type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining a protein structure\n",
    "### Experimental methods\n",
    "There exist experimental methods to deduce the structure of a protein.<br>\n",
    "Methods like *NMR (nuclear magnetic resonance)*, *X-Ray crystallography* aim to decode the shape of a protein based on experimental data.\n",
    "It is relevant to note that, although these methods are reliable, they require experimental data that is more often than not absent. Thus, depending principally on these methods can prove to be unpractical.\n",
    "\n",
    "### Methods based on statistics and neural networks\n",
    "The ability to sequence genome has given rise to the quantity of available protein information.<br>\n",
    "Maintained genome databases are constantly updated with new information. Thanks to the explosion of genetic information, it is possible to search the database for a known homologs of an unknown protein structure and obtain some intuition about its structure.<br> \n",
    "However, there are many protein sequences for which no known homologs are available. Being able to conjecture some characteristics of the shape of such proteins is convenient in providing indices about the protein's overall activity and structure.<br>\n",
    "An important observation has been performed by *Christian Anfinsen*, demonstrating that the three-dimensional shape of a protein is determined by the aminoacid sequences.\n",
    "\n",
    "\n",
    "A method to produce a  tertiary structure from a primary structure does not exist (*yet ?*). Nonetheless, methods based on statistical analysis and neural networks can be employed to derive a secondary structures.<br>\n",
    "An example of such methods is **GOR**, developed in the late 70s by **G**arnier-**O**sguthorpe-**R**obson.\n",
    "\n",
    "\n",
    "### GOR\n",
    "The GOR algorithm is a case study of statistical methods. The algorithm predicts the secondary structure of a protein based on its primary structure.\n",
    "\n",
    "#### Training based on a dataset\n",
    "GOR is a statistical method, it uses a dataset containing a large number of proteins for which the structure is known to compute statistical parameters. This phase is known as the *training phase*, as the algorithm uses large amounts of data to produce the best parameters used later in predictions.<br>\n",
    "The foundation of GOR lies in taking into consideration information about the placement and interactions between amino acids. Three types of information are employed:\n",
    "- Self-information: Information that the residue carries about its own conformation.\n",
    "- Directional information: Information about a conformation at a position $j$ carries by a residue at a position $i \\neq j$. It is independent of the type of aminoacid at $j$.\n",
    "- Pair information : Information about a conformation at a position $j$ carries by a residue at a position $i \\neq j$. Pair information takes into consideration the type of aminoacid at $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing the training\n",
    "Training involves performing statistical analysis on a dataset in order to obtain the values of frequency parameters. These parameters are required for predictions, in later phases.\n",
    "The statistical parameters are:\n",
    "- $f_{S_j}$ : Represents the number of times the structure $S_j$ occured accross the whole training set.\n",
    "- $f_{n-S_j}$ : Represents the number of times the structure $S_j$ did **not** occur accross the whole training set.\n",
    "- $f_{S_j,R_j}$ : Represents the number of times the structure $S_j$ occured with an aminoacid $R_j$ accross the whole training set.\n",
    "- $f_{n-S_j,R_j}$ : Represents the number of times the structure $S_j$ did **not** occur with an aminoacid $R_j$ accross the whole training set.\n",
    "- $f_{S_j, R_{j+m}, R_j}$ : Represents the number of times the structure $S_j$ occured with an aminoacid $R_j$ and having another aminoacid $X$ at a distance of $m$ from $R_j$; where $|m| < WINDOWSIZE$.\n",
    "- $f_{n-S_j, R_{j+m}, R_j}$ : Represents the number of times the structure $S_j$ did **not** occur having an aminoacid $R_j$ and another aminoacid $X$ at a distance of $m$ frpÃ¹ $R_j$; where $|m| < WINDOWSIZE$.\n",
    "\n",
    "##### Sliding Window\n",
    "GOR computed data include pair information and directional information. These require for a given amino acid to take into consideration its *context* (its position, what are its neighbors, and so forth).<br>\n",
    "This introduces complications on a computational scale, therefore an approximative method is used, called the *sliding Window*.\n",
    "For an aminoacid $R$ at a position j, the windown, with `WINDOWSIZE=8`, includes all neighbors of $R$ which are aminoacids at positions p:\n",
    "$$\n",
    "p \\in [j-m; j+m] \\cap [0; len(seq)-1] \\text{ where } m=WINDOWSIZE\n",
    "$$\n",
    "\n",
    "According to the original GOR paper (Garnier al 1996), this limit of 8 is not arbitrary but is based on studies of information content at increasing separations.\n",
    "\n",
    "##### Training implementation\n",
    "The training phase is done with the class `SurveyDic` which implementation is stated below.\n",
    "The object uses a Python dictionary structure to store the relevant data.\n",
    "Most notably, building up the information is done in the method `_build_survey`.\n",
    "The algorithm is based on the following algorithm (in pseudo-code):\n",
    "```\n",
    "# upon reading a particular aminoacid R at position j that is typed as S:\n",
    "f_S ++\n",
    "f_S_Rj ++\n",
    "for m in range(-8;8):\n",
    "  if m!= 0 and 0<=j+m<len(seq):\n",
    "    f_S_Rj+m_Rj_m ++\n",
    "```\n",
    "\n",
    "We note that since the training set is static, computing the dictionary each time might be unoptimized. Thus, we used *serialization* techniques to store the `SurveyDic` object in `survey.pkl` so we can read it instead of computing it on each execution. The serialization is done in the `save_to_file()` method. The unserialization is done by the function `unserialize_SurveyDic` which returns a `SurveyDic` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurveyDic:\n",
    "    STYPES = set('HEC')\n",
    "    AMINOACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    WINDOWSIZE = 8\n",
    "\n",
    "    def __init__(self, seq_fname, pkl_fname):\n",
    "        self.seq_fname = seq_fname\n",
    "        self.pkl_fname = pkl_fname\n",
    "        self.dic = dict()\n",
    "        self._build_dic()\n",
    "        self._build_survey()\n",
    "\n",
    "    def save_to_file(self):\n",
    "        with open(self.pkl_fname, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    def _build_dic(self):\n",
    "        for stype in self.STYPES:\n",
    "            self.dic[stype] = {'count': 0}\n",
    "            for aa in self.AMINOACIDS:\n",
    "                self.dic[stype][aa] = {'count': 0}\n",
    "                for aa2 in self.AMINOACIDS:\n",
    "                    self.dic[stype][aa][aa2] = dict()\n",
    "                    for m in range(1, self.WINDOWSIZE + 1):\n",
    "                        self.dic[stype][aa][aa2][-m] = 0\n",
    "                        self.dic[stype][aa][aa2][+m] = 0\n",
    "\n",
    "    def f_S(self, S):\n",
    "        return self.dic[S]['count']\n",
    "\n",
    "    def f_nS(self, S):\n",
    "        assert S in self.STYPES\n",
    "        return sum(self.f_S(S=stype) for stype in self.STYPES - set(S))\n",
    "\n",
    "    def f_S_R(self, S, R):\n",
    "        return self.dic[S][R]['count']\n",
    "\n",
    "    def f_nS_R(self, S, R):\n",
    "        assert S in self.STYPES\n",
    "        return sum(self.f_S_R(S=stype, R=R) for stype in self.STYPES - set(S))\n",
    "\n",
    "    def f_S_X_R(self, S, X, R, m):\n",
    "        return self.dic[S][R][X][m]\n",
    "\n",
    "    def f_nS_X_R(self, S, X, R, m):\n",
    "        assert S in self.STYPES\n",
    "        return sum(self.f_S_X_R(S=stype, X=X, R=R, m=m) for stype in self.STYPES - set(S))\n",
    "\n",
    "    def inc_S(self, S):\n",
    "        self.dic[S]['count'] += 1\n",
    "\n",
    "    def inc_SR(self, S, R):\n",
    "        self.dic[S][R]['count'] += 1\n",
    "\n",
    "    def inc_SXR(self, S, X, R, m):\n",
    "        self.dic[S][R][X][m] += 1\n",
    "\n",
    "    def _build_survey(self):\n",
    "        with open(self.seq_fname, 'r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                line = line.strip()\n",
    "                if line.startswith('>'):\n",
    "                    a_seq = f.readline().strip()\n",
    "                    s_seq = f.readline().strip()\n",
    "\n",
    "                    for j, a, s in zip(range(len(a_seq)), a_seq, s_seq):\n",
    "                        self.inc_S(s)\n",
    "                        self.inc_SR(s, a)\n",
    "                        for m in range(-self.WINDOWSIZE, self.WINDOWSIZE + 1):\n",
    "                            if m == 0:\n",
    "                                continue\n",
    "                            if not (0 <= j + m < len(a_seq)):\n",
    "                                continue\n",
    "                            aa2 = a_seq[j + m]\n",
    "                            self.inc_SXR(S=s, X=aa2, R=a, m=m)\n",
    "                line = f.readline()\n",
    "\n",
    "\n",
    "def unserialize_SurveyDic(pkl_fname):\n",
    "    with open(pkl_fname, 'rb') as f:\n",
    "        surveydic = pickle.load(f)\n",
    "    return surveydic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the secondary structure\n",
    "\n",
    "The GOR algorithm makes use of information theory developed by Shannon and Fano.<br>\n",
    "\n",
    "The quantity of information measures the amount of information that is brought by a specific \"event\".\n",
    "The quantity of information $I(S;R)$ is originally defined as follows:<br>\n",
    "\n",
    "$$\n",
    "I(S;R) = log[P(S|R)/P(S)]\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $S$ is one of the three conformations\n",
    "- $R$ is one of the 20 aminoacids\n",
    "- $P(S|R)$ the conditional probability for observing a conformation $S$ when a resiue $R$ is present\n",
    "- $P(S)$ is the probability of observing $S$\n",
    "\n",
    "\n",
    "Based on probabilities fundamental law, we have:\n",
    "$$\n",
    "P(S|R) = P(S,R)/P(R)\n",
    "$$\n",
    "where :\n",
    "\n",
    "- $P(S,R)$ is the probability of observing $S$ **and** $R$\n",
    "- $P(R)$ the probability of occurence of $R$ in nature.\n",
    "\n",
    "Since we are working with proteins, there is no way of having an exact theoretical value of the probabilities introduced above. Therefore, using the essential formula of probability $p(A) = \\frac{\\# occurence A}{\\#possibilities}$ (were $A$ is a particular event), we build our own estimations based on the observations in a large database.<br>\n",
    "Hence, we have the following:\n",
    "$$\n",
    "P(S, R) = f_{S,R}/N \\\\\n",
    "P(R)= f_R/N \\\\\n",
    "P(S) = f_S/N\n",
    "$$\n",
    "where:\n",
    "\n",
    "- $N$ is the total number of aminoacids in the database\n",
    "- $f_{S,R}$, $f_S$ and $f_R$ are counts explained in a previous section \"Performing the training\".<br>\n",
    "\n",
    "Consequently, we can deduce the following formula:\n",
    "$$\n",
    "I(S;R) = log( \\frac{f_{S,R}/f_R}{f_S/N})\n",
    "$$\n",
    "\n",
    "\n",
    "A more general form provides the difference of quantity of information ($\\Delta$) taking into account the quantity of information that the event of **not** having $S$ brings. This event is annotated $n-S$ where $n= \\{H, E, C\\}$, a set of all possible structure. <br>\n",
    "The more general form is defined as follows, it represents the **self-information**,  information that the residue carries about its own conformation.\n",
    "$$\n",
    "I(\\Delta S; R) = I(S;R) - I(n-S;R)=log(\\frac{f_{S,R}}{f_{n-S,R}}) + log(\\frac{f_{n-S}}{f_{S}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $n-S$ : event of **not** having the conformation S (= event of having the other conformations).\n",
    "- $f_{n-S}$ and $f_{n-S, R}$ are count explained in a previous section \"Performing the training\".<br>\n",
    "\n",
    "\n",
    "\n",
    "The equations above can be extented by taking into consideration the **context** of the occurence of the event.<br>\n",
    "The context is defined by the aminoacids surrounding the amino acid $R$ at a position $j$.<br>\n",
    "The following forumla determines the quantity of information brought by having $S$ at a position $j$ in the sequence composed by $R_1,...,R_n$:\n",
    "$$\n",
    "I(\\Delta S_j, R_1,R_2,...,R_n) = log[P(S_j, R_1,...,R_n)/P(n-S_j,R_1,..., R_n)] + log[P(n-S)/P(S)]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $S_j$ : event of having the conformation S at position $j$.\n",
    "- $R_x$: the aminoacid $R$ at position $x$.\n",
    "- $P(S_j, R_1,...,R_n)$ is the probability of occurence of S at a position $j$ in the sequence composed by $R_1,...,R_n$.\n",
    "- $P(n-S_j, R_1,...,R_n)$ is the probability of S **not** occuring at a position $j$ in the sequence composed by $R_1,...,R_n$.\n",
    "- $P(n-S)$ the probability of **not** having S in nature.\n",
    "\n",
    "A problem we face with such formula is determining the value of $P(S_j, R_1,...,R_n)$ which is impossible to calculate. Thus, we are required to employ approximations. We limit the context to a *window* with size 8. (*cfr.* Sliding window in the \"performing the training\" section.<br>\n",
    "The above formula using approximations becomes:\n",
    "$$\n",
    "I(\\Delta S_j, R_1,R_2,...,R_n) \\approx I(\\Delta S_j\\; R_j) + \\sum_{m=-8\\\\m\\neq0}^{m=8} I(\\Delta S_j\\; R_{j+m})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $R_{j+m}$ is an aminoacid $R$ at a position $j+m$.\n",
    "\n",
    "The first part of the formula ($I(\\Delta S_j\\; R_j)$ represents **self-information** whereas the other part ($\\sum_{m=-8\\\\m\\neq0}^{m=8} I(\\Delta S_j\\; R_{j+m}$) represents the **directional information**, which is information about a conformation at a position j carries by a residue at a position iâ j. It is independent of the type of aminoacid at j.\n",
    "\n",
    "Computed for the 3 types of structures (H,E and C), the highest value of the above equation determines the conformation of the aminoacid $R$ at position $j$.\n",
    "Hence; the conformation of an amino acid $R$ at $j$ is:\n",
    "$$\n",
    "conformation = argmax(I(\\Delta H_j, R_1,R_2,...,R_n), I(\\Delta E_j, R_1,R_2,...,R_n), I(\\Delta C_j, R_1,R_2,...,R_n))\n",
    "$$\n",
    "\n",
    "\n",
    "An additional approximation is introduced in GOR version 3 called the **pair information**, which is the information about a conformation at a position j carried by a residue at a position iâ j. Pair information takes into consideration the type of aminoacid at j. We now consider the correlation between the type of residues in the window and the type of the residue to be predicted. <br>\n",
    "Thus ,the new version of the formula is :\n",
    "$$\n",
    "I(\\Delta S_j, R_1,R_2,...,R_n) \\approx I(\\Delta S_j\\; R_j) + \\sum_{m=-8\\\\m\\neq0}^{m=8} I(\\Delta S_j; R_{j+m}|R_j)\n",
    "$$\n",
    "Where:\n",
    "\n",
    "$I(\\Delta S_j\\; R_{j+m}|R_j)$ is the quantity of information brought when having the conformation $S$ at a position $j$ and an aminoacid at a position $j+m$ in the window , *knowing that* the aminoacid $R$ occurs at position $j$.<br>\n",
    "This quantity is calculated with the following formula:\n",
    "$$\n",
    "I(\\Delta S_j\\; R_{j+m}|R_j) = log(\\frac{f_{S_j,R_{j+m},R_j}}{f_{n-S_j, R_{j+m},R_j}}) + log(\\frac{f_{n-S_j,R_j}}{f_{S_j,R_j}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GOR3:\n",
    "    \"\"\"\n",
    "    Basic GOR3: given a sequence and a SurveyDic predicts a secondary structure\n",
    "    \"\"\"\n",
    "    STYPES = 'HEC'\n",
    "\n",
    "    def __init__(self, a_seq, surveydic, protid=None):\n",
    "        self.protid = protid\n",
    "        self.a_seq = a_seq\n",
    "        self.sv = surveydic\n",
    "        self.predicted = ''\n",
    "        self._pretty_predicted = ''\n",
    "        self.integral_inf = []\n",
    "        self.build_structure()\n",
    "\n",
    "    def get_window_at(self, j):\n",
    "        \"\"\"\n",
    "        returns the window of aminoacid at position j in format {distance: aminoacid}\n",
    "        \"\"\"\n",
    "        window = dict()\n",
    "        for m in range(-8, 9):\n",
    "            if m != 0 and 0 <= j + m < len(self.a_seq):\n",
    "                window[m] = self.a_seq[j + m]\n",
    "        return window\n",
    "\n",
    "    def _I_delta(self, S, R):\n",
    "        \"\"\"\n",
    "        returns the qty of information having structure S associated to aminoacid R\n",
    "        \"\"\"\n",
    "        return log10(self.sv.f_S_R(S, R) / self.sv.f_nS_R(S, R)) + log10(self.sv.f_nS(S) / self.sv.f_S(S))\n",
    "\n",
    "    def _I_delta_ax(self, S, X, R, m):\n",
    "        \"\"\"\n",
    "        returns the qty of information having structure S associated to aminoacid R ;\n",
    "        having aminoacid X at distance m\n",
    "        \"\"\"\n",
    "        return log10(self.sv.f_S_X_R(S, X, R, m) / self.sv.f_nS_X_R(S, X, R, m)) + log10(\n",
    "            self.sv.f_nS_R(S, R) / self.sv.f_S_R(S, R))\n",
    "\n",
    "    def local_I(self, S, j):\n",
    "        \"\"\"\n",
    "        return qty of information having structure S at a position j.\n",
    "        This formula follows GOR3\n",
    "        \"\"\"\n",
    "        R = self.a_seq[j]\n",
    "        I = self._I_delta(S, R)\n",
    "        window = self.get_window_at(j)\n",
    "        for m in window.keys():\n",
    "            I += self._I_delta_ax(S=S, R=R, X=self.a_seq[j + m], m=m)\n",
    "        return I\n",
    "\n",
    "    def build_structure(self):\n",
    "        \"\"\"\n",
    "        Predicts the structure of the given aminoacid sequence a_seq\n",
    "        \"\"\"\n",
    "        self.predicted = ''\n",
    "        for j in range(len(self.a_seq)):\n",
    "            tmp = []\n",
    "            max_ = float('-inf'), None      # value, type  ; -inf initially to force reevaluation\n",
    "            for stype in self.STYPES:\n",
    "                I = self.local_I(S=stype, j=j)\n",
    "                if I > max_[0]:\n",
    "                    max_ = I, stype\n",
    "                tmp.append(I)\n",
    "            self.predicted += max_[1]\n",
    "            self.integral_inf.append(tuple(tmp))\n",
    "\n",
    "    def show_plot(self):\n",
    "        x = [i for i in range(len(self.a_seq))]\n",
    "        plt.plot(x, [y[0] for y in self.integral_inf], color='red', label=\"a-Helix\")  # I_H\n",
    "        plt.plot(x, [y[1] for y in self.integral_inf], color='blue', label=\"b-Strand\")  # I_E\n",
    "        plt.plot(x, [y[2] for y in self.integral_inf], color='green', label=\"Coil\")  # I_C\n",
    "        plt.legend()\n",
    "        plt.ylabel('Information Qty')\n",
    "        plt.xlabel('Position')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        s = '[*] Solution\\n'\n",
    "        if self.protid:\n",
    "            s += 'Protein ID: %s\\n' % self.protid\n",
    "        s += 'aminoacid sequence: %s\\n' % self.a_seq\n",
    "        s += 'predicted sequence: %s\\n' % (self.predicted if self.predicted else 'N/A')\n",
    "        s += \"length: %s\\n\" % len(self.a_seq)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dataset\n",
    "\n",
    "The GOR algorithm uses information based on the probability of finding an amino acid in a helix-$\\alpha$, a $\\beta$-strand or a coil in order to predict the secondary structure of the protein. To compute these probabilities, we need to use statistical data contained in the folder `dssp`.\n",
    "In this project, we are provided with the `dssp` folder that contains data of secondary structures of a $3713$ proteins (fetched from *WHATIF*). We will explain how to build a dataset using these data.\n",
    "\n",
    "Our dataset is split into  parts, a *training set* and a *test set* which contain respectively the first $3000$ proteins and the remaining $713$ proteins.<br>\n",
    "The training set is used to calculate various parameters based on statistical analysis that will be useful for predictions. The test set is used to evaluate the performance and quality of our predictions.<br>\n",
    "\n",
    "Each protein is composed of multiple chains.  Parsing and using all chains of all proteins would be computationally difficult to achieve in the scope of this project. Therefore, we are provided with `CATH_info.txt`, a file indicating which chains to be parsed for each protein.\n",
    "\n",
    "\n",
    "#### Parsing a DSSP entry\n",
    "The DSSP files hold information about the proteins as well as their structure.\n",
    "Here is an example segment a DSSP file taken from 1A2P.dssp:\n",
    "```\n",
    " #  RESIDUE AA STRUCTURE BP1 BP2  ACC     N-H-->O    O-->H-N    N-H-->O    O-->H-N    TCO  KAPPA ALPHA  PHI   PSI    X-CA   Y-CA   Z-CA \n",
    "    1    3 A V              0   0  132      0, 0.0     2,-0.7     0, 0.0    46,-0.0   0.000 360.0 360.0 360.0 129.8   18.0   38.6   42.8\n",
    "    2    4 A I        +     0   0   64      1,-0.1    19,-0.2     5,-0.1     0, 0.0  -0.906 360.0 135.3-107.1 108.1   19.6   41.8   44.1\n",
    "    3    5 A N        +     0   0   26     -2,-0.7    72,-3.1    71,-0.1    73,-0.2   0.241  33.0 106.3-141.9  23.5   20.3   44.0   41.1\n",
    "    4    6 A T  S  > S-     0   0   66     70,-0.2     4,-2.5    71,-0.1     5,-0.4  -0.574  76.2-111.7-100.6 163.9   19.2   47.6   41.9\n",
    "    5    7 A F  H  > S+     0   0   29     -2,-0.2     4,-2.1     1,-0.2     5,-0.2   0.947 118.9  39.3 -56.0 -49.1   21.3   50.6   42.7\n",
    "    6    8 A D  H  > S+     0   0  100      2,-0.2     4,-2.3     1,-0.2     5,-0.2   0.923 116.2  51.1 -71.8 -38.0   20.1   50.7   46.3\n",
    "```\n",
    "As we can observe, the third, fourth and fifth columns provide meaningful data about the chain identifier, the aminoacid and the type of (secondary) structure of that aminoacid. We note that no information in the fifth column, the structure type column, represents a coil as well. <br>\n",
    "The function `parse_dssp_line` takes in parameter a line (entry) of a file and returns its relevant data in a tuple format: `(chain_id, aminoacid, structure_type)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dssp_line(line):\n",
    "    \"\"\" Given line in dssp return chainid, aminoacid, stype \"\"\"\n",
    "    re_data = re.findall(r\"^\\d+\\s+-?\\d+[A-Z\\s](.)\\s(.)\\s\\s(.)\\s+.+\\d+\", line)\n",
    "    assert (len(re_data) == 1 and len(re_data[0]) == 3 and re_data[0][0].isalnum() and re_data[0][\n",
    "        1].isalpha() and re_data[0][2] in {'H', 'G', 'I', 'E', 'B', 'T', 'C', 'S', ' '})\n",
    "    return re_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing CATH_info\n",
    "Parsing all chains of all proteins would be computationally difficult in the scope of this project.\n",
    "`CATH_info.txt` indicates which chains to be parsed for each protein.\n",
    "The format of an entry in CATH_info is:\n",
    "`protein_id+chain_id` <br>\n",
    "\n",
    "We note that there are more than $3713$ entries in the `CATH_info.txt` file because in some cases we are asked to parse multiple chains from the same protein. <br>\n",
    "The function `parse_cathinfo` takes in parameter the cath_info file path and returns a dictionary that contains which chains to parse for each protein, in the format: `{protein_id: [chains to parse]}`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cathinfo(cath_info_fname):\n",
    "    \"\"\" Return dictionary proteinid:[chains to parse] from CATH_info\"\"\"\n",
    "    data = OrderedDict()\n",
    "    with open(cath_info_fname, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line.strip()\n",
    "            line = line.split()[0]\n",
    "            filename = line[:4]\n",
    "            chain_id = line[-1]\n",
    "            if filename in data:\n",
    "                data[filename].append(chain_id)\n",
    "            else:\n",
    "                data[filename] = [chain_id]\n",
    "            line = f.readline()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing the DSSP folder :<br>\n",
    "\n",
    "The `dssp` folder contains data of secondary structures of a large variety of proteins (3713 proteins exactly).<br>\n",
    "To build a dataset, we need to parse each protein of the dssp folder according to the `CATH_info.txt` file.<br>\n",
    "This is achieved by the function `parse_dssp` which returns the parsed data in as a list of protein objects.\n",
    "The function first uses `parse_cath_info` to extract information about which chain to parse, then proceeds to read the files and store the data in the dictionary.<br>\n",
    "\n",
    "We note that the amino acids in lowercase represent Cysteines.\n",
    "Aminoacids X, Z, and B are ignored because the probability of their occurrence is 0, according to the data of Swissprot (discussed in the previous project).\n",
    "\n",
    "<br>\n",
    "The function is defined as follows, it uses a `Protein` structure to store data for practical purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protein:\n",
    "    def __init__(self, protid):\n",
    "        self.protid = protid\n",
    "        self.name = ''\n",
    "        self.organism = ''\n",
    "        self.chains = dict()\n",
    "        \n",
    "        \n",
    "def parse_dssp(dssp_path, cath_info_fname):\n",
    "    \"\"\" given path to dssp and cath_info, return list of protein objects \"\"\"\n",
    "    cathinfo_dic = parse_cathinfo(cath_info_fname)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    # parsing\n",
    "    for protid in cathinfo_dic.keys():\n",
    "        protein = Protein(protid=protid)\n",
    "        dssp_file = '%s/%s.dssp' % (dssp_path, protid)\n",
    "        with open(dssp_file, 'r') as f:\n",
    "            # seek start of relevant data\n",
    "            line = f.readline()\n",
    "            while not line.strip().startswith('#'):\n",
    "                # name of prot\n",
    "                if line.startswith('COMPND'):\n",
    "                    re_data = re.findall(r'MOLECULE:\\s(.+);', line)\n",
    "                    protein.name = re_data[0] if re_data else ''\n",
    "                # organism\n",
    "                elif line.startswith('SOURCE'):\n",
    "                    re_data = re.findall(r'ORGANISM_SCIENTIFIC:\\s(.+);', line)\n",
    "                    protein.organism = re_data[0] if re_data else ''\n",
    "                line = f.readline()\n",
    "\n",
    "            # start reading relevant data\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                line = line.strip()\n",
    "                try:\n",
    "                    chaind_id, aminoacid, stype = parse_dssp_line(line)\n",
    "                    # lower char amino acids are C\n",
    "                    if aminoacid.islower():\n",
    "                        aminoacid = 'C'\n",
    "                    # register if correct chain and not XZB\n",
    "                    if chaind_id in cathinfo_dic[protid] and aminoacid not in {'X', 'Z', 'B'}:\n",
    "                        if chaind_id in cathinfo_dic[protid]:\n",
    "                            if chaind_id in protein.chains.keys():\n",
    "                                protein.chains[chaind_id]['a_seq'] += aminoacid\n",
    "                                protein.chains[chaind_id]['s_seq'] += simplify_stype(stype)\n",
    "                            else:\n",
    "                                protein.chains[chaind_id] = {'a_seq': aminoacid, 's_seq': simplify_stype(stype)}\n",
    "                        else:\n",
    "                            raise Exception(\"logic error\")\n",
    "\n",
    "                except AssertionError as e:\n",
    "                    assert ('!' in line)\n",
    "                finally:\n",
    "                    line = f.readline()\n",
    "        out.append(protein)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the training and test dataset :<br>\n",
    "The training set contains the first $3000$ proteins. The set will be used to compute statistical parameters.<br>\n",
    "The test set contains the remaining $713$ proteins. The set will be used to test the quality of our algorithm.<br>\n",
    "Building a dataset is done with the function `make_train_test_set`. It uses `parse_dssp` to gather the data of all proteins in a dictionary, then split and write them to the training and test files, `train.txt` and `test.txt` respectively.<br>\n",
    "The format of an entry in the datasets is:\n",
    "```\n",
    "> protein_id|protein_name|organism\n",
    "aminoacid_sequence\n",
    "structure_seq\n",
    "```\n",
    "The function is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_entry(fp, protein, chain_id):\n",
    "    \"\"\"\n",
    "    Given aminoacid and structure sequence write to dataset file\n",
    "    fp: file pointer\n",
    "    protein: protein object\n",
    "    chain_id: chain to write\n",
    "    \"\"\"\n",
    "    a_seq = protein.chains[chain_id]['a_seq']\n",
    "    s_seq = protein.chains[chain_id]['s_seq']\n",
    "    header = \">%s|%s|%s\" % (protein.protid, protein.name, protein.organism)\n",
    "    body = \"%s\\n%s\" % (a_seq, s_seq)\n",
    "    to_write = header + '\\n' + body + '\\n'\n",
    "    fp.write(to_write)\n",
    "\n",
    "\n",
    "def make_train_test_set(out_train_fname, out_test_fname, dssp_path, cath_info_fname, nprot_train=3000):\n",
    "    \"\"\"\n",
    "    out_train_fname: filename of training dataset\n",
    "    out_test_fname: filename of test_dataset\n",
    "    dssp_path: path of the dssp folder where dssp files are present\n",
    "    cath_info_fname: filename of the cath_info file\n",
    "    nprot_train: number of proteins for the training set\n",
    "    \"\"\"\n",
    "    proteins = parse_dssp(dssp_path=dssp_path, cath_info_fname=cath_info_fname)\n",
    "    total_c = 0  # total entries count\n",
    "    prot_c = 0  # proteins count\n",
    "\n",
    "    # writing the training set\n",
    "    with open(out_train_fname, 'w') as f:\n",
    "        for protein in proteins[:nprot_train]:\n",
    "            prot_c += 1\n",
    "            for chain_id in protein.chains.keys():\n",
    "                write_dataset_entry(f, protein, chain_id)\n",
    "                #print('written %s %s - %s to train' % (prot_c, total_c, protein.protid))\n",
    "                total_c += 1\n",
    "\n",
    "    # writing the test set\n",
    "    with open(out_test_fname, 'w') as f:\n",
    "        for protein in proteins[nprot_train:]:\n",
    "            prot_c += 1\n",
    "            for chain_id in protein.chains.keys():\n",
    "                write_dataset_entry(f, protein, chain_id)\n",
    "                # print('written %s %s - %s to test' % (prot_c, total_c, protein.protid))\n",
    "                total_c += 1\n",
    "    print('Finished writing datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the quality of a structure prediction\n",
    "Testing the performance and quality of our predictor is crucial because it establishes the degree of trust we can give the predictor. We test the quality of our implementation by performing predictions on <u>completely new</u> proteins for which the true structure sequence is known. Such proteins are stored in the test dataset `TEST_FILE`. For each of these predictions, we have consequentially the $Q_3$, $MCC_H$, $MCC_C$ and $MCC_E$ parameters representing the accuracy of this *individual* prediction (quality of one prediction).<br>\n",
    "\n",
    "#### Q3\n",
    "\n",
    "The prediction accuracy $Q3$ represents the percentage of accurracy of the secondary structure predicted against the original structure.<br>\n",
    "$Q_3$ is calculcated as follows:\n",
    "$$\n",
    "Q_3 (\\%) = \\frac{ N_{ correctly\\_predicted\\_residues}}{N_{residues}}\n",
    "$$\n",
    "\n",
    "We note that the pure random $Q_3$ is $1/3 (1/3\\alpha, 1/3\\beta, 1/3 coil) \\approx 0.38 $.<br>\n",
    "It is possible to have badly predicted sequences that give a greater $Q_3$ than the pure random accuracy.<br>\n",
    "Therefore, this parameter alone is not relevant and should always be accompanied by other statistical parameters, such as $MCC$.\n",
    "\n",
    "Example Q3 evaluation on a sequence of 26 residues:<br>\n",
    "<img src=\"img/q3.png\" >\n",
    "\n",
    "#### MCCx\n",
    "The MCC (Matthew Correlation Coefficient) analysis is used in machine learning to measure the quality of predictions. It takes in consideration true/false positives and negatives to scope the accuracy of predictions.\n",
    "\n",
    "MCC is type-specific. It means that, in our case, it studies the accuracy of the prediction from the point of view of a specific shape category, $c$ in this instance.\n",
    "The prediction of a structure all come down to 4 possible cases:\n",
    "\n",
    "Possible cases for $MCC_c$, where $c$ is the shape we're analysing and $d$ any other shape having $c \\neq d$:\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-cly1{text-align:left;vertical-align:middle}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-cly1\">case</th>\n",
    "    <th class=\"tg-cly1\">Predicted</th>\n",
    "    <th class=\"tg-cly1\">Original</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-cly1\">TP</td>\n",
    "    <td class=\"tg-cly1\">c<br></td>\n",
    "    <td class=\"tg-cly1\">c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-cly1\">TN<br></td>\n",
    "    <td class=\"tg-cly1\">d</td>\n",
    "    <td class=\"tg-cly1\">d</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">FP</td>\n",
    "    <td class=\"tg-0lax\">c</td>\n",
    "    <td class=\"tg-0lax\">d</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">FN</td>\n",
    "    <td class=\"tg-0lax\">d</td>\n",
    "    <td class=\"tg-0lax\">c</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "$MCC$ is calculated as follows:\n",
    "$$\n",
    "MCC = \\frac{TP \\cdot TN - FP \\cdot FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}} \\text{ and } mcc \\in [-1;1]\n",
    "$$\n",
    "\n",
    "The value of the MCC represents the effectiveness of the predictor.\n",
    "\n",
    "<img src=\"img/mcc_chartx.png\">\n",
    "\n",
    "\n",
    "Example of MCC:\n",
    "<img src=\"img/mcc.png\">\n",
    "\n",
    "We note that considering the form of $(TP+FP)(TP+FN)(TN+FP)(TN+FN)$, having any factor equals to $0$ yields a zero division case while computing the $MCC$. We remediate to this situation by arbitrarily setting $(TP+FP)(TP+FN)(TN+FP)(TN+FN)=1$.\n",
    "More precisely, if one of the factors at the denominator is 0 since it is an addition of 2 positive integers, we have that both of the operands are null. In this case, the numerator $TP \\cdot TN - FP \\cdot FN$ is 0 as well and $mcc=0$, counting as a pure random guess\n",
    "\n",
    "In this project, we will make use of both $Q_3$ and $MCC_x$ to evaluate the quality of our predictions.\n",
    "More precisely, we will compute the mean and standard deviation values of $Q_3$ and $MCC_x$ after having predicted a wide set of new protein sequences. This task is performed in a farther section.\n",
    "\n",
    "\n",
    "The predictions and evaluations can be done with the subclass `GOR3Evaluator` defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GOR3Evaluator(GOR3):\n",
    "    \"\"\"\n",
    "    Evaluator for the GOR3 algorithm, in contrast with GOR3 class,\n",
    "    GOR3Evaluator takes into consideration the true structure sequence \"s_seq\"\n",
    "    \"\"\"\n",
    "    def __init__(self, a_seq, s_seq, surveydic, protid=None):\n",
    "        super().__init__(a_seq=a_seq, surveydic=surveydic, protid=protid)\n",
    "        self.s_seq = s_seq\n",
    "\n",
    "    def q3(self):\n",
    "        \"\"\"\n",
    "        Returns the Q3 of the evaluation\n",
    "        \"\"\"\n",
    "        if not self.predicted:\n",
    "            return 0\n",
    "        count_correct = 0\n",
    "        for s1, s2 in zip(self.s_seq, self.predicted):\n",
    "            if s1 == s2:\n",
    "                count_correct += 1\n",
    "        return round(count_correct / len(self.s_seq) * 100, 3)\n",
    "\n",
    "    def mcc(self, S):\n",
    "        \"\"\"\n",
    "        Returns the MCC_S of the evaluation where S is a structure type\n",
    "        \"\"\"\n",
    "        if not self.predicted:\n",
    "            return 0\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for s1, s2 in zip(self.s_seq, self.predicted):\n",
    "            if s1 == s2:\n",
    "                if s1 == S:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if s1 == S:\n",
    "                    fn += 1\n",
    "                elif s2 == S:\n",
    "                    fp += 1\n",
    "        try:  # todo : check zero div case\n",
    "            res = ((tp * tn) - (fp * fn)) / (((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5)\n",
    "        except ZeroDivisionError:\n",
    "            res = ((tp * tn) - (fp * fn)) / 1\n",
    "        return round(res, 3)\n",
    "\n",
    "    def _make_pretty_predicted_str(self):\n",
    "        \"\"\"\n",
    "        Make the predicited sequence pretty with colors\n",
    "        RED: prediction error\n",
    "        GREEN: correct prediction\n",
    "        \"\"\"\n",
    "        GREEN = \"\\u001b[32m\"\n",
    "        RED = \"\\u001b[31m\"\n",
    "        RST = '\\u001b[0m'\n",
    "\n",
    "        curr_green = None\n",
    "        for s1, s2 in zip(self.predicted, self.s_seq):\n",
    "            if s1 == s2:\n",
    "                if curr_green is False or curr_green is None:\n",
    "                    self._pretty_predicted += GREEN\n",
    "                    curr_green = True\n",
    "            else:\n",
    "                if curr_green is True or curr_green is None:\n",
    "                    self._pretty_predicted += RED\n",
    "                    curr_green = False\n",
    "            self._pretty_predicted += s1\n",
    "        self._pretty_predicted += RST\n",
    "\n",
    "    @property\n",
    "    def pretty_predicted(self):\n",
    "        \"\"\"\n",
    "        Returns the pretty string version of the prediction\n",
    "        \"\"\"\n",
    "        if self._pretty_predicted == '':\n",
    "            assert self.predicted != ''\n",
    "            self._make_pretty_predicted_str()\n",
    "        return self._pretty_predicted\n",
    "\n",
    "    def __str__(self):\n",
    "        s = '[*] Solution\\n'\n",
    "        if self.protid:\n",
    "            s += 'Protein ID: %s\\n' % self.protid\n",
    "        s += 'aminoacid sequence: %s\\n' % self.a_seq\n",
    "        s += 'structure sequence: %s\\n' % self.s_seq\n",
    "        s += 'predicted sequence: %s\\n' % (self.pretty_predicted if self.predicted else 'N/A')\n",
    "        s += \"length: %s\\n\" % len(self.a_seq)\n",
    "        s += 'Q3: %s %%\\n' % self.q3()\n",
    "        for stype in self.STYPES:\n",
    "            s += 'MCC_%s: %s \\n' % (stype, self.mcc(stype))\n",
    "        return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and discussion\n",
    "\n",
    "We define essential constants and file paths required to the use of the programs in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'rsrc/dataset/train.txt'\n",
    "TEST_FILE = 'rsrc/dataset/test.txt'\n",
    "PKL_TRAIN_DATA_FILE = 'rsrc/dataset/survey.pkl'\n",
    "DSSP_PATH = 'rsrc/dataset/dssp'\n",
    "DSSP_TEST_PATH = 'rsrc/dataset/dssp_test'\n",
    "CATHINFO_FILE = 'rsrc/dataset/CATH_info.txt'\n",
    "CATHINFO_TEST_FILE = 'rsrc/dataset/CATH_info_test.txt'\n",
    "STYPES = 'HEC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the training and test datasets\n",
    "\n",
    "We start by building the training and test datasets. These are required for training and evaluating the performance of the GOR algorithm. The function `make_train_test_set` generates the 2 files in the `dssp` folder, as defined previously by constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_test_set(\n",
    "    out_train_fname=TRAIN_FILE,\n",
    "    out_test_fname=TEST_FILE,\n",
    "    dssp_path=DSSP_PATH,\n",
    "    cath_info_fname=CATHINFO_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase\n",
    "In this phase, we train our algorithm by computing the statistical parameters of the training dataset, namely:\n",
    "- $f_{S_j}$ & $f_{n-S_j}$\n",
    "- $f_{S_j,R_j}$ & $f_{n-S_j,R_j}$\n",
    "- $f_{S_j, R_{j+m}, R_j}$ & $f_{n-S_j, R_{j+m}, R_j}$\n",
    "<br>\n",
    "We use the training set `TRAIN_FILE` which contains 3000 proteins.\n",
    "The results are serialized in a pickle file for eventual reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveydic = SurveyDic(TRAIN_FILE, pkl_fname=PKL_TRAIN_DATA_FILE)\n",
    "surveydic.save_to_file()\n",
    "\n",
    "surveydic_test = SurveyDic(TEST_FILE, 'rsrc/dataset/testsurvey.pkl')  # used later in discussions\n",
    "surveydic_test.save_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation phase\n",
    "For each of these predictions, we have consequentially the $Q_3$, $MCC_H$, $MCC_C$ and $MCC_E$ parameters representing the accuracy of this *individual* prediction.<br>\n",
    "The individual degree of precision of an individual prediction is insignificant alone because it doesn't consider other prediction cases.<br> Therefore, the **global** quality for the predictor is determined by computing the mean value and standard deviation of each of these parameters for a wide set of new proteins.\n",
    "\n",
    "The testing of our implementation is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q3_list = []\n",
    "mcc = {stype: [] for stype in STYPES}\n",
    "\n",
    "with open(TEST_FILE, 'r') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.strip()\n",
    "        a_seq = f.readline().strip()\n",
    "        s_seq = f.readline().strip()\n",
    "        gor = GOR3Evaluator(a_seq=a_seq, s_seq=s_seq, surveydic=surveydic)\n",
    "\n",
    "        # log individual quality data\n",
    "        q3_list.append(gor.q3())\n",
    "        for stype in mcc.keys():\n",
    "            mcc[stype].append(gor.mcc(stype))\n",
    "        line = f.readline()\n",
    "\n",
    "# output results\n",
    "print('[*] Statistical analysis results')\n",
    "print('Q3: mean:%.3f  -  sd:%.3f' % (mean(q3_list), stdev(q3_list)))\n",
    "for stype in mcc.keys():\n",
    "    print('MCC %s: mean:%.3f  -  sd:%.3f' % (stype, mean(mcc[stype]), stdev(mcc[stype])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q3 boxplot\n",
    "plt.boxplot(q3_list)\n",
    "plt.title('Q3 - Boxplot')\n",
    "plt.ylabel('Q3')\n",
    "plt.show()\n",
    "\n",
    "# Q3 violin plot\n",
    "plt.violinplot(q3_list, showmeans=True, showmedians=True)\n",
    "plt.title('Q3 - Violin plot')\n",
    "plt.ylabel('Q3')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# MCC boxplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(mcc.values())\n",
    "fig.suptitle('MCC for test set')\n",
    "plt.ylabel('MCC')\n",
    "ax.set_xticklabels(mcc.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and discussions on the quality of predictions\n",
    "\n",
    "#### Observations on Q3\n",
    "The mean value of Q3 is $\\mu =61.297\\%$ with a standard deviation of $\\sigma = 7.327 \\%$ .<br>\n",
    "The standard deviation $\\sigma$ represents the degree of compactness of the observed data.  A standard deviation of $\\sigma=7.327\\%$ means that the mean value of $Q3$ could be fluctuating on a distance of $\\pm 7.327 \\%$.\n",
    "\n",
    "\n",
    "As observed on the boxplot, the interquartile range $IQR$ is $\\approx IQR \\in [58, 68] %$. This means that $50 \\%$ of Q3 values are contained within this range.<br>. Furthermore, the statistical maximum is observed to be $\\approx 80\\%$. The statistical minimum is observed to be $\\approx 45\\%$, which is **greater** than a pure random $Q3$ value of $38\\%$ by $\\approx 1.5$ standard deviations ($\\sigma = 7.327$). This indicates that statistically in worst cases, the GOR3 algorithm still performs better than a random solution. More precisely, even in worst cases, the GOR3 algorithm provides a higher entropy than a random guess.<br>\n",
    "We note that a random Q3 is calculated by $Q_3 \\approx (1/3\\alpha, 1/3\\beta, 1/3 coil) \\approx 0.38 $.<br>\n",
    "\n",
    "Although outliners exist (values not contained within the statistical minimum-maximum range), we can observe on the violin plot of Q3 that the density of the probability of these occurrences is marginally low. <br>\n",
    "\n",
    "In addition, we notice that the data is spread more or less symmetrically. This could be an indicator that our dataset is unbiased and correctly formed.<br>\n",
    "\n",
    "The theorical value of the mean and standard deviation $Q_3$ for the GOR3 algorithm as presented in the original paper *\"GOR Method for Predicting Protein Secondary Structure from Amino Acid Sequence\"* slightly differ from our presented results:\n",
    "    \n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-noaz{background-color:#ffffff;color:#333333;border-color:inherit;text-align:left;vertical-align:middle}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-noaz\"></th>\n",
    "    <th class=\"tg-noaz\">Present</th>\n",
    "    <th class=\"tg-noaz\">Expected<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-noaz\">Q3 mean (%)<br></td>\n",
    "    <td class=\"tg-noaz\">61.297<br></td>\n",
    "    <td class=\"tg-noaz\">63.3<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-noaz\">Q3 stdev (%)</td>\n",
    "    <td class=\"tg-noaz\">7.327</td>\n",
    "    <td class=\"tg-noaz\">0.8</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "The $Q3=61.23\\%$ factor is approximately equal to the expected factor of $63.3\\%$.\n",
    "We observe that the standard deviation $\\mu$ is significantly lower in the original paper than our results.\n",
    "These difference can be caused by multiple effects:\n",
    "In fact, the dataset we use is different from the one used in the paper. GOR researchers used a training dataset containing proteins having a resolution better than 2.5 Ã with an R factor less than 25% and whose length is greater than 50 residues. No pairs have an identity $>30\\%$. This differs from our dataset, in which the wide majority of sequences have indeed a length greater than 50 residues, but we are not guaranteed to have the same features regarding the resolution, the R factor and the identity upper bound of $30\\%$.\n",
    "Additionally, the datasets used by the researchers to train and test the predictor consisted of 267 and 266 proteins which is lower than out train and test datasets which consist of 3000 and 713 proteins.<br>\n",
    "All these divergences could lead to a different *compactness* of the observed results, thus a different standard deviation.\n",
    "\n",
    "#### Observations on MCC\n",
    "\n",
    "MCC values are contained within the range [-1,1] where 1 represents an excellent predictor with 100% True positives and true negatives. 0 represents a random predictor where 50% of predictions are true and the remaining 50% false (negatives or positives).-1 represents a predictor with 100% false positives and false negatives.\n",
    "In our case, the mean MCC for all structure types is on average $\\mu \\approx 0.35$.\n",
    "This indicates that our predictor, although not perfect, performs reasonably better than random ($0$).<br>\n",
    "\n",
    "The mean values of the observed $MCC$s are:\n",
    " - $\\mu_{MCC_H} = 0.34 \\text{ and } \\sigma_{MCC_H}=0.16$\n",
    " - $\\mu_{MCC_E} = 0.33 \\text{ and } \\sigma_{MCC_E}=0.16$\n",
    " - $\\mu_{MCC_C} = 0.36 \\text{ and } \\sigma_{MCC_C}=0.12$\n",
    " \n",
    "The standard deviation of $MCC$ represents in a way the *stability* of our predictions.\n",
    "The standard deviation for all MCCs is on average $\\sigma=0.15$ which is relatively high because $\\sigma \\approx \\mu / 2$. We see that although the predictions are on average satisfactory, the predictor has not acquired yet enough \"maturity\" to steadily yield adequate results. We might produce better stability with a bigger training set.<br>\n",
    "\n",
    "\n",
    "Looking at $f_H$, $f_E$ and $f_C$ of the test and training sets (computed below), we remark that $f_E < f_H < f_C$ for both sets, which is in harmony with the observed $MCC$s, where; $MCC_E < MCC_H < MCC_C$.\n",
    "Thus, we hypothesize that the abundancy of a structure in the dataset affects its MCC.\n",
    "\n",
    "Observing the boxplots, we notice the statistical minimum for $H$ and $E$ is 0 (representing pure random).<br>\n",
    "We notice that the data is not spread symmetrically. Lower bound outliners are significantly more present than upper bound outliners (specifically for $H$ and $E$). These outliners have an $mcc<0$ meaning that their predictions performed **worse** than random ($0$).<br>\n",
    "This observation helps us see the <u>difference between MCC and Q3</u>, where Q3 implied that GOR3 performs better than random, even in worst cases.<br>\n",
    "\n",
    "We note that the statistical MCC minimum for $C$ ($0.1$) is higher than the statistical minimum of $H$ and $E$ (both $0$) because $f_E < f_H < f_C$. Therefore, we can say that in our case, the prediction of the $C$ type is of better quality than the prediction of $H$ and $E$ types.  This deduction is consequently reflected on $\\sigma_{MCC_C}$ which is lower than $\\sigma_{MCC_H}$ and $\\sigma_{MCC_E}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abundancy of structure types in datasets\n",
    "print('TRAINING: f_H:%s; f_E:%s; f_C:%s' % (surveydic.f_S('H'), surveydic.f_S('E'), surveydic.f_S('C') ))\n",
    "print('TEST: f_H:%s; f_E:%s; f_C:%s' % (surveydic_test.f_S('H'), surveydic_test.f_S('E'), surveydic_test.f_S('C') ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting secondary structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look more precisely at the predictions performed by our GOR implementation.\n",
    "We are provided with a few proteins in the `dssp_test` folder (along with their `CATH_info_test.txt` file) for which we will be analyzing the predictions of secondary structure.\n",
    "\n",
    "We start first by parsing the required proteins in `dssp_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PURE_TEST_SET = parse_dssp(dssp_path=DSSP_TEST_PATH, cath_info_fname=CATHINFO_TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we apply the GOR3 algorithm to each of this protein in order to predict their secondary structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_list_puretest = []\n",
    "\n",
    "for protein in PURE_TEST_SET:\n",
    "    for chain_id in protein.chains.keys():\n",
    "        a_seq = protein.chains[chain_id]['a_seq']\n",
    "        s_seq = protein.chains[chain_id]['s_seq']\n",
    "        gor = GOR3Evaluator(a_seq=a_seq, s_seq=s_seq, surveydic=surveydic, protid=protein.protid)\n",
    "        print(gor)\n",
    "        q3_list_puretest.append(gor.q3())\n",
    "        gor.show_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and discussions on the predictions\n",
    "The previous test is done on a small set of proteins of varying length.<br>\n",
    "\n",
    "We didn't use colors because these display differently on different jupyter installations, causing compatibility issues. A colored version is available at `img/coloured_p3.png`.\n",
    "\n",
    "\n",
    "At first glance, we observe that the length of the protein sequence doesn't seem to have any impact on the outcome or the quality of the predictions.<br>\n",
    "The accuracy of the predicted structures are fluctuating around the computed mean Q3, which is $\\approx 61\\%$.<br>\n",
    "\n",
    "Looking at the prediction of 1HMO, we see that the MCC of the conformation E is 0. This is explained by the fact that no conformation E appears in the real structure and MCC of E is solely formed of True negatives and False positives. Therefore, True positives and false negatives are both equal to 0, $TP \\cdot TN - FP \\cdot FN=0$ making the value of $MCC_E=0$.\n",
    "\n",
    "We notice that the proteins 1AVM and 1MHO yield results better the mean Q3, with $66.667 \\%$ and $66.832\\%$. Particularly, we remark that the MCCs for 1AVM are relatively high, compared to the average MCCs observed in previous sections, with 0.415, 0.348 and 0.497 against 0.34, 0.33 and 0.36. Furthermore, observing the plot of 1AVM, we see that in general, the quantity of information of conformations that have **not** been selected is negative, meaning the correct information particularly stands out and the algorithm is assertive with its prediction.<br>\n",
    "This behavior is suspiciously better than the ones observed for other predictions.<br>\n",
    "This behavior leads us to suspect that the training set contains extremely similar homologs to 1AVM, and 1MHO to a lower degree.<br>\n",
    "This hypothesis can be tested using the previously implemented *NeedlemanWunsch* or *SmithWaterman* algorithms.\n",
    "However, considering the size of the training set, such an experiment is computationally difficult. Therefore, we decided to use a custom made <u>heuristic</u> algorithm to find relevant proteins in the training set.\n",
    "\n",
    "The algorithms evaluates the similarities in the proteins' name to detect potentially relevant related proteins.\n",
    "The algorithm operates as follows:\n",
    "```\n",
    "for each protein p in dssp_test:\n",
    "   similars_count = 0\n",
    "   for each protein p1 in training set:\n",
    "       if  string_similarity(p.name, p1.name) >= minimum_similarity:\n",
    "          similars_count += 1\n",
    "  print(similars_count)\n",
    "```\n",
    "\n",
    "We use python's `difflib.SequenceMatcher`, based on *\"Gestalt pattern matching\" Ratcliff and Obershelp 1980*, to compute string similarities.\n",
    "\n",
    "The function is defined as follows along with a helper function that parses our dataset file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(filename):\n",
    "    out = []\n",
    "    with open(filename, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                pid, pname, org = line.split('|')\n",
    "                a_seq = f.readline().strip()\n",
    "                s_seq = f.readline().strip()\n",
    "                out.append( (pid, pname, org, a_seq, s_seq))\n",
    "            line = f.readline()\n",
    "    return out\n",
    "\n",
    "def find_similar_by_name(dssp_test_path, cathinfo_test, dataset_filename, similarity=0.7):\n",
    "    to_test_data = parse_dssp(dssp_path=dssp_test_path, cath_info_fname=cathinfo_test)\n",
    "    train_data = parse_dataset(dataset_filename)\n",
    "    results = OrderedDict()\n",
    "\n",
    "    print('{*} Testing against %s with minimum name similarity: %s' % (dataset_filename, similarity))\n",
    "    for protein in to_test_data:\n",
    "        count = 0\n",
    "        for pid, pname, porg, a_seq, s_seq in train_data:\n",
    "            s = SequenceMatcher(isjunk=lambda x: x in '0123456789', a=protein.name, b=pname)\n",
    "            #s = SequenceMatcher(isjunk=None, a=protein.name, b=pname)\n",
    "            if protein.name in pname or s.ratio() >= similarity:\n",
    "                #print(pname)\n",
    "                count += 1\n",
    "        results[protein.protid] = count\n",
    "        print('%s-%s : %d' % (protein.protid, protein.name, count))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to search in the training set for proteins with **minimum 80% similarity** compared to the proteins we are testing.<br>\n",
    "Based on the previously emitted hypothesis, we expect to have numerous similarities for 1AVM, a few similarities for 1HMO and minimal or None for other proteins, namely 1ARL,1AVA, and 1HGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_similarity_res = find_similar_by_name(\n",
    "    dssp_test_path=DSSP_TEST_PATH,\n",
    "    cathinfo_test=CATHINFO_TEST_FILE,\n",
    "    dataset_filename=TRAIN_FILE,\n",
    "    similarity=0.8\n",
    "    )\n",
    "\n",
    "# plot scatter\n",
    "plt.scatter(q3_list_puretest, list(name_similarity_res.values()))\n",
    "plt.title(\"Scatter graph showing the correlation of the quality of prediction and the presence of related proteins in the training set\")\n",
    "plt.xlabel(\"Q3\")\n",
    "plt.ylabel('Number of related-by-name proteins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there are $14$ proteins with similar names ($80\\%$) to 1AVM and $2$ proteins with similar names to 1HMO whereas 0 proteins with similar names to the other proteins,  These results are compatible with our expectations thus validating our hypothesis. Besides, the scatter figure is visually consistent with our deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In conclusion, we examine in this report the prediction of proteins secondary structure using the GOR3 algorithm. Key principles are explained and illustrated throughout the report.<br>\n",
    "\n",
    "The algorithm is implemented and evaluated in an attempt to make sense of different concepts. The results are analyzed, compared to the theoretical expected values and discussed accordingly in an attempt to produce hypotheses about the outcome.<br>\n",
    "\n",
    "We can safely say that predicting the structure of a protein sequence, as is with all machine learning algorithms, depends considerably on the dataset used for training. Although GOR3 predictions are satisfactory enough, better results can be achieved by GOR5, a later version of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- A mathematical theory of communications, Shannon - http://www.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf\n",
    "- M.Zvelebil, J.O.Baum, (2008). Understanding bioinformatics\n",
    "- GOR Method for Predicting Protein Secondary Structure from Amino Acid Sequence, GARNIER, GIBRAT, ROBSON\n",
    "- https://www.uniprot.org/\n",
    "- https://publications.nigms.nih.gov/psi/timeline_text.html\n",
    "- GOR5 Server, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2553678/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "468px",
    "width": "423px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
